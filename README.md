# ğŸ“ ArXiv Daily Institution Paper Collector

> Automatically collect the latest Computer Science papers from arXiv, filter by date, classify by research institutions (Google, OpenAI, MIT, etc.), and download full PDFs into folders by **date â†’ organization**.

---

## ğŸ” Key Features

âœ… Fetches **latest arXiv CS papers** (auto pagination)  
âœ… Filters by **Beijing local date** (Published / Updated mode selectable)  
âœ… Classifies papers by **institutions / universities / labs**  
âœ… Downloads **full original PDFs** (no merge required)  
âœ… Folder structure:

```

output_org_pdfs/
â””â”€â”€ YYYY-MM-DD/
â”œâ”€â”€ Google/
â”œâ”€â”€ OpenAI/
â”œâ”€â”€ MIT/
â””â”€â”€ ...

```

âœ… Supports **fallback per-organization search** to ensure maximum coverage  
âœ… Easily expandable to new organizations (Microsoft, Tsinghua, Berkeley, etc.)

---

## ğŸ—‚ Project Structure

```

arxiv_daily_org_pdfs/
â”œâ”€ app.py                # Main entry â€“ fetch, filter, classify, download
â”œâ”€ config.py             # Settings: timezone, org regex, paging, window mode
â”œâ”€ fetch_arxiv.py        # arXiv API caller with retry & fallback endpoints
â”œâ”€ filters.py            # Time-window filtering (published/updated)
â”œâ”€ classify.py           # Regex-based institution grouping
â”œâ”€ downloader.py         # Concurrent PDF downloader (with ID fix)
â”œâ”€ utils.py              # Time helpers, folder path utils
â”œâ”€ requirements.txt      # Python dependencies
â””â”€ README.md             # Documentation

````

---

## âš™ï¸ Installation

```bash
git clone https://github.com/yourname/arxiv-daily-institutions.git
cd arxiv-daily-institutions
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
pip install -r requirements.txt
````

---

## ğŸ•’ Configuration (`config.py`)

### 1ï¸âƒ£ Control how many papers to fetch (pagination)

```python
MAX_RESULTS_PER_PAGE = 200    # per API page
MAX_PAGES = 2                 # 2 pages = ~400 recent papers
```

### 2ï¸âƒ£ Time Window Mode (IMPORTANT)

```python
WINDOW_FIELD = "updated"   # "updated" | "published" | "both"
```

| Mode        | Meaning                                                  |
| ----------- | -------------------------------------------------------- |
| `updated`   | Catch papers with **any update yesterday (v2, v3)**      |
| `published` | Only papers **first submitted yesterday**                |
| `both`      | Very strict: papers both *published & updated* yesterday |

### 3ï¸âƒ£ Add / Expand Institutions

```python
INSTITUTIONS_PATTERNS = {
    "Google":  [...],
    "MIT":     [...],
    "OpenAI":  [...],
}
```

---

## ğŸš€ Run the Collector

```bash
python app.py
```

---

## ğŸ§ª DRY-RUN Mode (Only simulate, don't download)

In `config.py`:

```python
DRY_RUN = True
LIMIT_PER_ORG = 2   # Only show 2 papers per org (for testing)
```

---

## ğŸ“ Output Example

```
output_org_pdfs/
â””â”€â”€ 2025-10-14/
    â”œâ”€â”€ Google/
    â”‚   â”œâ”€â”€ 2503.12345v2.pdf
    â”œâ”€â”€ OpenAI/
    â”‚   â”œâ”€â”€ 2504.09876v1.pdf
    â”œâ”€â”€ MIT/
    â”‚   â”œâ”€â”€ 2504.19176v2.pdf
```

---

## ğŸ›¡ï¸ Network Resilience

* Custom **User-Agent**
* Automatic retry with **fallback URLs**
* Supports **NO_PROXY** for direct arXiv access

---

## ğŸ”§ Automation (Optional)

### Cron (Linux server)

```
0 8 * * *  /usr/bin/python3 /path/to/app.py
```

### GitHub Actions (UTC 00:00 â†’ Beijing 08:00)

```yaml
schedule:
  - cron: "0 0 * * *"
```

---

## ğŸ§© Extending Institutions

Track any combination of:

| Category      | Examples                  |
| ------------- | ------------------------- |
| Big Tech      | OpenAI, Anthropic, Amazon |
| China AI Labs | Huawei, Baidu, SenseTime  |
| Universities  | MIT, Stanford, Tsinghua   |
| Research Orgs | AI2, LAION, EleutherAI    |

Just edit:

```
INSTITUTIONS_PATTERNS
ORG_SEARCH_TERMS
```

---

## ğŸ› Troubleshooting

| Issue           | Fix                                     |
| --------------- | --------------------------------------- |
| 404 on PDF      | Canonical `.pdf` fallback enabled       |
| SSL timeout     | Uses HTTP fallback + retry              |
| No papers found | Increase MAX_PAGES & check WINDOW_FIELD |

---

## ğŸ¤ Contributions

Feel free to submit:

* Better institution regex
* New organization tracking
* Feature requests (like mailing, Web UI)

---

## ğŸ“œ License

MIT License â€“ You are free to modify and automate.

---

### ğŸŒŸ Enjoy research without manual filtering!

If this project saves you time, consider starring â­ or sharing it!

```
